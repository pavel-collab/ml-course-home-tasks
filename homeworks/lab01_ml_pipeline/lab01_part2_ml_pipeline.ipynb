{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-86e0de040aac317a",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "# Lab assignment â„–1, part 2\n",
    "\n",
    "This lab assignment consists of several parts. You are supposed to make some transformations, train some models, estimate the quality of the models and explain your results.\n",
    "\n",
    "Several comments:\n",
    "* Don't hesitate to ask questions, it's a good practice.\n",
    "* No private/public sharing, please. The copied assignments will be graded with 0 points.\n",
    "* Blocks of this lab will be graded separately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__*This is the second part of the assignment. First and third parts are waiting for you in the same directory.*__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-512ba712fc0fc065",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Part 2. Data preprocessing, model training and evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b656a4266174b009",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### 1. Reading the data\n",
    "Today we work with the [dataset](https://archive.ics.uci.edu/ml/datasets/Statlog+%28Vehicle+Silhouettes%29), describing different cars for multiclass ($k=4$) classification problem. The data is available below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If on colab, uncomment the following lines\n",
    "\n",
    "# ! wget https://raw.githubusercontent.com/girafe-ai/ml-course/22f_made/homeworks/lab01_ml_pipeline/car_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-eebac6bfdf73d0bc",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(846, 19) (846,)\n",
      "(549, 19) (549,) (297, 19) (297,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset = pd.read_csv('car_data.csv', delimiter=',', header=None).values\n",
    "data = dataset[:, :-1].astype(int)\n",
    "target = dataset[:, -1]\n",
    "\n",
    "print(data.shape, target.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.35)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-88b1a0f688568f2c",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "To get some insights about the dataset, `pandas` might be used. The `train` part is transformed to `pd.DataFrame` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>108</td>\n",
       "      <td>80</td>\n",
       "      <td>44</td>\n",
       "      <td>68</td>\n",
       "      <td>135</td>\n",
       "      <td>59</td>\n",
       "      <td>8</td>\n",
       "      <td>150</td>\n",
       "      <td>45</td>\n",
       "      <td>19</td>\n",
       "      <td>145</td>\n",
       "      <td>170</td>\n",
       "      <td>329</td>\n",
       "      <td>173</td>\n",
       "      <td>80</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>180</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>624</td>\n",
       "      <td>84</td>\n",
       "      <td>36</td>\n",
       "      <td>75</td>\n",
       "      <td>136</td>\n",
       "      <td>55</td>\n",
       "      <td>6</td>\n",
       "      <td>140</td>\n",
       "      <td>48</td>\n",
       "      <td>18</td>\n",
       "      <td>125</td>\n",
       "      <td>166</td>\n",
       "      <td>290</td>\n",
       "      <td>138</td>\n",
       "      <td>71</td>\n",
       "      <td>4</td>\n",
       "      <td>36</td>\n",
       "      <td>189</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>666</td>\n",
       "      <td>102</td>\n",
       "      <td>43</td>\n",
       "      <td>96</td>\n",
       "      <td>197</td>\n",
       "      <td>63</td>\n",
       "      <td>10</td>\n",
       "      <td>185</td>\n",
       "      <td>36</td>\n",
       "      <td>22</td>\n",
       "      <td>142</td>\n",
       "      <td>202</td>\n",
       "      <td>513</td>\n",
       "      <td>139</td>\n",
       "      <td>65</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>195</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>791</td>\n",
       "      <td>86</td>\n",
       "      <td>43</td>\n",
       "      <td>68</td>\n",
       "      <td>150</td>\n",
       "      <td>64</td>\n",
       "      <td>9</td>\n",
       "      <td>138</td>\n",
       "      <td>48</td>\n",
       "      <td>18</td>\n",
       "      <td>143</td>\n",
       "      <td>161</td>\n",
       "      <td>285</td>\n",
       "      <td>174</td>\n",
       "      <td>69</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>192</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>566</td>\n",
       "      <td>108</td>\n",
       "      <td>54</td>\n",
       "      <td>103</td>\n",
       "      <td>212</td>\n",
       "      <td>65</td>\n",
       "      <td>11</td>\n",
       "      <td>208</td>\n",
       "      <td>32</td>\n",
       "      <td>24</td>\n",
       "      <td>162</td>\n",
       "      <td>228</td>\n",
       "      <td>648</td>\n",
       "      <td>240</td>\n",
       "      <td>71</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>90</td>\n",
       "      <td>104</td>\n",
       "      <td>55</td>\n",
       "      <td>107</td>\n",
       "      <td>222</td>\n",
       "      <td>68</td>\n",
       "      <td>11</td>\n",
       "      <td>218</td>\n",
       "      <td>31</td>\n",
       "      <td>24</td>\n",
       "      <td>173</td>\n",
       "      <td>232</td>\n",
       "      <td>703</td>\n",
       "      <td>229</td>\n",
       "      <td>71</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>188</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>693</td>\n",
       "      <td>90</td>\n",
       "      <td>46</td>\n",
       "      <td>75</td>\n",
       "      <td>133</td>\n",
       "      <td>55</td>\n",
       "      <td>11</td>\n",
       "      <td>160</td>\n",
       "      <td>43</td>\n",
       "      <td>20</td>\n",
       "      <td>161</td>\n",
       "      <td>173</td>\n",
       "      <td>369</td>\n",
       "      <td>171</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>182</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>72</td>\n",
       "      <td>92</td>\n",
       "      <td>39</td>\n",
       "      <td>91</td>\n",
       "      <td>191</td>\n",
       "      <td>62</td>\n",
       "      <td>8</td>\n",
       "      <td>176</td>\n",
       "      <td>37</td>\n",
       "      <td>21</td>\n",
       "      <td>137</td>\n",
       "      <td>196</td>\n",
       "      <td>466</td>\n",
       "      <td>151</td>\n",
       "      <td>67</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>192</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>326</td>\n",
       "      <td>106</td>\n",
       "      <td>49</td>\n",
       "      <td>96</td>\n",
       "      <td>201</td>\n",
       "      <td>61</td>\n",
       "      <td>10</td>\n",
       "      <td>181</td>\n",
       "      <td>36</td>\n",
       "      <td>21</td>\n",
       "      <td>158</td>\n",
       "      <td>197</td>\n",
       "      <td>494</td>\n",
       "      <td>180</td>\n",
       "      <td>62</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>202</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>492</td>\n",
       "      <td>85</td>\n",
       "      <td>43</td>\n",
       "      <td>66</td>\n",
       "      <td>130</td>\n",
       "      <td>57</td>\n",
       "      <td>6</td>\n",
       "      <td>151</td>\n",
       "      <td>45</td>\n",
       "      <td>19</td>\n",
       "      <td>143</td>\n",
       "      <td>173</td>\n",
       "      <td>333</td>\n",
       "      <td>168</td>\n",
       "      <td>86</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>180</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>258</td>\n",
       "      <td>99</td>\n",
       "      <td>48</td>\n",
       "      <td>104</td>\n",
       "      <td>196</td>\n",
       "      <td>63</td>\n",
       "      <td>10</td>\n",
       "      <td>201</td>\n",
       "      <td>33</td>\n",
       "      <td>23</td>\n",
       "      <td>152</td>\n",
       "      <td>221</td>\n",
       "      <td>604</td>\n",
       "      <td>199</td>\n",
       "      <td>73</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>188</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>646</td>\n",
       "      <td>90</td>\n",
       "      <td>38</td>\n",
       "      <td>79</td>\n",
       "      <td>185</td>\n",
       "      <td>69</td>\n",
       "      <td>6</td>\n",
       "      <td>160</td>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "      <td>130</td>\n",
       "      <td>178</td>\n",
       "      <td>393</td>\n",
       "      <td>133</td>\n",
       "      <td>66</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>198</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>92</td>\n",
       "      <td>104</td>\n",
       "      <td>52</td>\n",
       "      <td>100</td>\n",
       "      <td>191</td>\n",
       "      <td>59</td>\n",
       "      <td>9</td>\n",
       "      <td>197</td>\n",
       "      <td>33</td>\n",
       "      <td>23</td>\n",
       "      <td>158</td>\n",
       "      <td>218</td>\n",
       "      <td>583</td>\n",
       "      <td>234</td>\n",
       "      <td>70</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>191</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>792</td>\n",
       "      <td>100</td>\n",
       "      <td>51</td>\n",
       "      <td>104</td>\n",
       "      <td>163</td>\n",
       "      <td>52</td>\n",
       "      <td>10</td>\n",
       "      <td>206</td>\n",
       "      <td>32</td>\n",
       "      <td>23</td>\n",
       "      <td>164</td>\n",
       "      <td>217</td>\n",
       "      <td>631</td>\n",
       "      <td>193</td>\n",
       "      <td>69</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>188</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>661</td>\n",
       "      <td>110</td>\n",
       "      <td>46</td>\n",
       "      <td>100</td>\n",
       "      <td>197</td>\n",
       "      <td>61</td>\n",
       "      <td>9</td>\n",
       "      <td>193</td>\n",
       "      <td>34</td>\n",
       "      <td>22</td>\n",
       "      <td>149</td>\n",
       "      <td>209</td>\n",
       "      <td>561</td>\n",
       "      <td>160</td>\n",
       "      <td>65</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>194</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1   2    3    4   5   6    7   8   9    10   11   12   13  14  15  \\\n",
       "0   108   80  44   68  135  59   8  150  45  19  145  170  329  173  80   7   \n",
       "1   624   84  36   75  136  55   6  140  48  18  125  166  290  138  71   4   \n",
       "2   666  102  43   96  197  63  10  185  36  22  142  202  513  139  65   8   \n",
       "3   791   86  43   68  150  64   9  138  48  18  143  161  285  174  69   6   \n",
       "4   566  108  54  103  212  65  11  208  32  24  162  228  648  240  71   9   \n",
       "5    90  104  55  107  222  68  11  218  31  24  173  232  703  229  71   3   \n",
       "6   693   90  46   75  133  55  11  160  43  20  161  173  369  171  77   0   \n",
       "7    72   92  39   91  191  62   8  176  37  21  137  196  466  151  67   3   \n",
       "8   326  106  49   96  201  61  10  181  36  21  158  197  494  180  62  19   \n",
       "9   492   85  43   66  130  57   6  151  45  19  143  173  333  168  86   4   \n",
       "10  258   99  48  104  196  63  10  201  33  23  152  221  604  199  73   8   \n",
       "11  646   90  38   79  185  69   6  160  40  20  130  178  393  133  66   2   \n",
       "12   92  104  52  100  191  59   9  197  33  23  158  218  583  234  70  10   \n",
       "13  792  100  51  104  163  52  10  206  32  23  164  217  631  193  69   5   \n",
       "14  661  110  46  100  197  61   9  193  34  22  149  209  561  160  65  11   \n",
       "\n",
       "    16   17   18  \n",
       "0   12  180  185  \n",
       "1   36  189  195  \n",
       "2   12  195  204  \n",
       "3    0  192  201  \n",
       "4    0  189  197  \n",
       "5   10  188  199  \n",
       "6   16  182  192  \n",
       "7   23  192  200  \n",
       "8   15  202  209  \n",
       "9    9  180  183  \n",
       "10   4  188  197  \n",
       "11  14  198  205  \n",
       "12  10  191  198  \n",
       "13  21  188  196  \n",
       "14   7  194  203  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pd = pd.DataFrame(X_train)\n",
    "\n",
    "# First 15 rows of our dataset.\n",
    "X_train_pd.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-98e7d91d77d65fcf",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Methods `describe` and `info` deliver some useful information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "      <td>549.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>423.327869</td>\n",
       "      <td>93.426230</td>\n",
       "      <td>44.754098</td>\n",
       "      <td>81.420765</td>\n",
       "      <td>167.457195</td>\n",
       "      <td>61.581056</td>\n",
       "      <td>8.444444</td>\n",
       "      <td>167.542805</td>\n",
       "      <td>41.218579</td>\n",
       "      <td>20.488160</td>\n",
       "      <td>147.755920</td>\n",
       "      <td>187.278689</td>\n",
       "      <td>433.023679</td>\n",
       "      <td>173.759563</td>\n",
       "      <td>72.644809</td>\n",
       "      <td>6.296903</td>\n",
       "      <td>12.504554</td>\n",
       "      <td>188.803279</td>\n",
       "      <td>195.462659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>249.980207</td>\n",
       "      <td>8.215867</td>\n",
       "      <td>6.123397</td>\n",
       "      <td>15.489448</td>\n",
       "      <td>32.983579</td>\n",
       "      <td>7.300090</td>\n",
       "      <td>4.403374</td>\n",
       "      <td>32.662570</td>\n",
       "      <td>7.777444</td>\n",
       "      <td>2.542763</td>\n",
       "      <td>14.510586</td>\n",
       "      <td>30.369391</td>\n",
       "      <td>172.550303</td>\n",
       "      <td>31.929675</td>\n",
       "      <td>7.369019</td>\n",
       "      <td>5.040458</td>\n",
       "      <td>8.790883</td>\n",
       "      <td>6.179604</td>\n",
       "      <td>7.443765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>131.000000</td>\n",
       "      <td>191.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>181.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>205.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>314.000000</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>184.000000</td>\n",
       "      <td>190.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>426.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>363.000000</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>197.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>641.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>196.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>217.000000</td>\n",
       "      <td>578.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>193.000000</td>\n",
       "      <td>201.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>845.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>306.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>261.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>287.000000</td>\n",
       "      <td>998.000000</td>\n",
       "      <td>264.000000</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>211.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2           3           4           5   \\\n",
       "count  549.000000  549.000000  549.000000  549.000000  549.000000  549.000000   \n",
       "mean   423.327869   93.426230   44.754098   81.420765  167.457195   61.581056   \n",
       "std    249.980207    8.215867    6.123397   15.489448   32.983579    7.300090   \n",
       "min      0.000000   73.000000   33.000000   42.000000  104.000000   47.000000   \n",
       "25%    205.000000   87.000000   40.000000   70.000000  140.000000   57.000000   \n",
       "50%    426.000000   93.000000   44.000000   79.000000  166.000000   61.000000   \n",
       "75%    641.000000   99.000000   49.000000   96.000000  194.000000   65.000000   \n",
       "max    845.000000  117.000000   59.000000  110.000000  306.000000  126.000000   \n",
       "\n",
       "               6           7           8           9           10          11  \\\n",
       "count  549.000000  549.000000  549.000000  549.000000  549.000000  549.000000   \n",
       "mean     8.444444  167.542805   41.218579   20.488160  147.755920  187.278689   \n",
       "std      4.403374   32.662570    7.777444    2.542763   14.510586   30.369391   \n",
       "min      2.000000  114.000000   26.000000   17.000000  118.000000  131.000000   \n",
       "25%      6.000000  145.000000   33.000000   19.000000  137.000000  167.000000   \n",
       "50%      8.000000  156.000000   43.000000   20.000000  146.000000  178.000000   \n",
       "75%     10.000000  196.000000   46.000000   23.000000  158.000000  217.000000   \n",
       "max     55.000000  261.000000   59.000000   28.000000  188.000000  287.000000   \n",
       "\n",
       "               12          13          14          15          16          17  \\\n",
       "count  549.000000  549.000000  549.000000  549.000000  549.000000  549.000000   \n",
       "mean   433.023679  173.759563   72.644809    6.296903   12.504554  188.803279   \n",
       "std    172.550303   31.929675    7.369019    5.040458    8.790883    6.179604   \n",
       "min    191.000000  112.000000   59.000000    0.000000    0.000000  176.000000   \n",
       "25%    314.000000  149.000000   68.000000    2.000000    5.000000  184.000000   \n",
       "50%    363.000000  173.000000   72.000000    5.000000   11.000000  188.000000   \n",
       "75%    578.000000  198.000000   76.000000    9.000000   18.000000  193.000000   \n",
       "max    998.000000  264.000000  127.000000   22.000000   41.000000  206.000000   \n",
       "\n",
       "               18  \n",
       "count  549.000000  \n",
       "mean   195.462659  \n",
       "std      7.443765  \n",
       "min    181.000000  \n",
       "25%    190.000000  \n",
       "50%    197.000000  \n",
       "75%    201.000000  \n",
       "max    211.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pd.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 549 entries, 0 to 548\n",
      "Data columns (total 19 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   0       549 non-null    int64\n",
      " 1   1       549 non-null    int64\n",
      " 2   2       549 non-null    int64\n",
      " 3   3       549 non-null    int64\n",
      " 4   4       549 non-null    int64\n",
      " 5   5       549 non-null    int64\n",
      " 6   6       549 non-null    int64\n",
      " 7   7       549 non-null    int64\n",
      " 8   8       549 non-null    int64\n",
      " 9   9       549 non-null    int64\n",
      " 10  10      549 non-null    int64\n",
      " 11  11      549 non-null    int64\n",
      " 12  12      549 non-null    int64\n",
      " 13  13      549 non-null    int64\n",
      " 14  14      549 non-null    int64\n",
      " 15  15      549 non-null    int64\n",
      " 16  16      549 non-null    int64\n",
      " 17  17      549 non-null    int64\n",
      " 18  18      549 non-null    int64\n",
      "dtypes: int64(19)\n",
      "memory usage: 81.6 KB\n"
     ]
    }
   ],
   "source": [
    "X_train_pd.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-be844269be69c387",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### 2. Machine Learning pipeline\n",
    "Here you are supposed to perform the desired transformations. Please, explain your results briefly after each task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.0. Data preprocessing\n",
    "* Make some transformations of the dataset (if necessary). Briefly explain the transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-a1514aa189a49fca",
     "locked": false,
     "points": 15,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>95</th>\n",
       "      <th>48</th>\n",
       "      <th>83</th>\n",
       "      <th>178</th>\n",
       "      <th>72</th>\n",
       "      <th>10</th>\n",
       "      <th>162</th>\n",
       "      <th>42</th>\n",
       "      <th>20</th>\n",
       "      <th>159</th>\n",
       "      <th>176</th>\n",
       "      <th>379</th>\n",
       "      <th>184</th>\n",
       "      <th>70</th>\n",
       "      <th>6</th>\n",
       "      <th>16</th>\n",
       "      <th>187</th>\n",
       "      <th>197</th>\n",
       "      <th>van</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>91</td>\n",
       "      <td>41</td>\n",
       "      <td>84</td>\n",
       "      <td>141</td>\n",
       "      <td>57</td>\n",
       "      <td>9</td>\n",
       "      <td>149</td>\n",
       "      <td>45</td>\n",
       "      <td>19</td>\n",
       "      <td>143</td>\n",
       "      <td>170</td>\n",
       "      <td>330</td>\n",
       "      <td>158</td>\n",
       "      <td>72</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>189</td>\n",
       "      <td>199</td>\n",
       "      <td>van</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>104</td>\n",
       "      <td>50</td>\n",
       "      <td>106</td>\n",
       "      <td>209</td>\n",
       "      <td>66</td>\n",
       "      <td>10</td>\n",
       "      <td>207</td>\n",
       "      <td>32</td>\n",
       "      <td>23</td>\n",
       "      <td>158</td>\n",
       "      <td>223</td>\n",
       "      <td>635</td>\n",
       "      <td>220</td>\n",
       "      <td>73</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>188</td>\n",
       "      <td>196</td>\n",
       "      <td>saab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>93</td>\n",
       "      <td>41</td>\n",
       "      <td>82</td>\n",
       "      <td>159</td>\n",
       "      <td>63</td>\n",
       "      <td>9</td>\n",
       "      <td>144</td>\n",
       "      <td>46</td>\n",
       "      <td>19</td>\n",
       "      <td>143</td>\n",
       "      <td>160</td>\n",
       "      <td>309</td>\n",
       "      <td>127</td>\n",
       "      <td>63</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>199</td>\n",
       "      <td>207</td>\n",
       "      <td>van</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>85</td>\n",
       "      <td>44</td>\n",
       "      <td>70</td>\n",
       "      <td>205</td>\n",
       "      <td>103</td>\n",
       "      <td>52</td>\n",
       "      <td>149</td>\n",
       "      <td>45</td>\n",
       "      <td>19</td>\n",
       "      <td>144</td>\n",
       "      <td>241</td>\n",
       "      <td>325</td>\n",
       "      <td>188</td>\n",
       "      <td>127</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>180</td>\n",
       "      <td>183</td>\n",
       "      <td>bus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>107</td>\n",
       "      <td>57</td>\n",
       "      <td>106</td>\n",
       "      <td>172</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>255</td>\n",
       "      <td>26</td>\n",
       "      <td>28</td>\n",
       "      <td>169</td>\n",
       "      <td>280</td>\n",
       "      <td>957</td>\n",
       "      <td>264</td>\n",
       "      <td>85</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>181</td>\n",
       "      <td>183</td>\n",
       "      <td>bus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>841</td>\n",
       "      <td>93</td>\n",
       "      <td>39</td>\n",
       "      <td>87</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>169</td>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "      <td>134</td>\n",
       "      <td>200</td>\n",
       "      <td>422</td>\n",
       "      <td>149</td>\n",
       "      <td>72</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>188</td>\n",
       "      <td>195</td>\n",
       "      <td>saab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>842</td>\n",
       "      <td>89</td>\n",
       "      <td>46</td>\n",
       "      <td>84</td>\n",
       "      <td>163</td>\n",
       "      <td>66</td>\n",
       "      <td>11</td>\n",
       "      <td>159</td>\n",
       "      <td>43</td>\n",
       "      <td>20</td>\n",
       "      <td>159</td>\n",
       "      <td>173</td>\n",
       "      <td>368</td>\n",
       "      <td>176</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>186</td>\n",
       "      <td>197</td>\n",
       "      <td>van</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>843</td>\n",
       "      <td>106</td>\n",
       "      <td>54</td>\n",
       "      <td>101</td>\n",
       "      <td>222</td>\n",
       "      <td>67</td>\n",
       "      <td>12</td>\n",
       "      <td>222</td>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "      <td>173</td>\n",
       "      <td>228</td>\n",
       "      <td>721</td>\n",
       "      <td>200</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>187</td>\n",
       "      <td>201</td>\n",
       "      <td>saab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>844</td>\n",
       "      <td>86</td>\n",
       "      <td>36</td>\n",
       "      <td>78</td>\n",
       "      <td>146</td>\n",
       "      <td>58</td>\n",
       "      <td>7</td>\n",
       "      <td>135</td>\n",
       "      <td>50</td>\n",
       "      <td>18</td>\n",
       "      <td>124</td>\n",
       "      <td>155</td>\n",
       "      <td>270</td>\n",
       "      <td>148</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>190</td>\n",
       "      <td>195</td>\n",
       "      <td>saab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>845</td>\n",
       "      <td>85</td>\n",
       "      <td>36</td>\n",
       "      <td>66</td>\n",
       "      <td>123</td>\n",
       "      <td>55</td>\n",
       "      <td>5</td>\n",
       "      <td>120</td>\n",
       "      <td>56</td>\n",
       "      <td>17</td>\n",
       "      <td>128</td>\n",
       "      <td>140</td>\n",
       "      <td>212</td>\n",
       "      <td>131</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>186</td>\n",
       "      <td>190</td>\n",
       "      <td>van</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>845 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0   95  48   83  178   72  10  162  42  20  159  176  379  184   70  \\\n",
       "0      1   91  41   84  141   57   9  149  45  19  143  170  330  158   72   \n",
       "1      2  104  50  106  209   66  10  207  32  23  158  223  635  220   73   \n",
       "2      3   93  41   82  159   63   9  144  46  19  143  160  309  127   63   \n",
       "3      4   85  44   70  205  103  52  149  45  19  144  241  325  188  127   \n",
       "4      5  107  57  106  172   50   6  255  26  28  169  280  957  264   85   \n",
       "..   ...  ...  ..  ...  ...  ...  ..  ...  ..  ..  ...  ...  ...  ...  ...   \n",
       "840  841   93  39   87  183   64   8  169  40  20  134  200  422  149   72   \n",
       "841  842   89  46   84  163   66  11  159  43  20  159  173  368  176   72   \n",
       "842  843  106  54  101  222   67  12  222  30  25  173  228  721  200   70   \n",
       "843  844   86  36   78  146   58   7  135  50  18  124  155  270  148   66   \n",
       "844  845   85  36   66  123   55   5  120  56  17  128  140  212  131   73   \n",
       "\n",
       "      6  16  187  197   van  \n",
       "0     9  14  189  199   van  \n",
       "1    14   9  188  196  saab  \n",
       "2     6  10  199  207   van  \n",
       "3     9  11  180  183   bus  \n",
       "4     5   9  181  183   bus  \n",
       "..   ..  ..  ...  ...   ...  \n",
       "840   7  25  188  195  saab  \n",
       "841   1  20  186  197   van  \n",
       "842   3   4  187  201  saab  \n",
       "843   0  25  190  195  saab  \n",
       "844   1  18  186  190   van  \n",
       "\n",
       "[845 rows x 20 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### YOUR CODE HERE\n",
    "# output aour data as a dataframe\n",
    "raw_dataset = pd.read_csv('car_data.csv')\n",
    "raw_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset['van']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we can see, target colomn is a categorial, so, we need to represent it as number\n",
    "# Also, we should to scale dataset and remove the first colomn, cause it's just an index of element, \n",
    "# it doesn't include any information about objects\n",
    "\n",
    "\n",
    "# Importing LabelEncoder from Sklearn \n",
    "# library from preprocessing Module.\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    " \n",
    "# Creating a instance of label Encoder.\n",
    "le = LabelEncoder()\n",
    " \n",
    "# Using .fit_transform function to fit label\n",
    "# encoder and return encoded label\n",
    "label = le.fit_transform(df['van'])\n",
    " \n",
    "# printing label\n",
    "label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. Basic logistic regression\n",
    "* Find optimal hyperparameters for logistic regression with cross-validation on the `train` data (small grid/random search is enough, no need to find the *best* parameters).\n",
    "\n",
    "* Estimate the model quality with `f1` and `accuracy` scores.\n",
    "* Plot a ROC-curve for the trained model. For the multiclass case you might use `scikitplot` library (e.g. `scikitplot.metrics.plot_roc(test_labels, predicted_proba)`).\n",
    "\n",
    "*Note: please, use the following hyperparameters for logistic regression: `multi_class='multinomial'`, `solver='saga'` `tol=1e-3` and ` max_iter=500`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-1dd5ad5d0845cbbb",
     "locked": false,
     "points": 5,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7231313131313131, 0.7231313131313131, 0.7231313131313131, 0.7231313131313131, 0.7231313131313131, 0.7231313131313131, 0.7231313131313131, 0.7231313131313131, 0.7231313131313131, 0.7231313131313131, 0.7231313131313131, 0.7231313131313131, 0.7231313131313131, 0.7231313131313131, 0.7231313131313131, 0.7231313131313131, 0.724983164983165, 0.724983164983165, 0.724983164983165, 0.724983164983165]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pavel/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "### YOUR CODE HERE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#! firstly use a draft implementation with variation of solver\n",
    "l1_rati_list = np.linspace(0, 1, 20)\n",
    "cros_val_scores = []\n",
    "for l1 in l1_rati_list:\n",
    "    # LogisticRegression\n",
    "    clf = LogisticRegression(multi_class='multinomial',\n",
    "                            solver='saga',\n",
    "                            tol=1e-3,\n",
    "                            max_iter=500,\n",
    "                            penalty='elasticnet',\n",
    "                            l1_ratio=l1,\n",
    "                            random_state=0)\n",
    "    scores = cross_val_score(clf, X_train, y_train, cv=10, scoring='accuracy')\n",
    "    cros_val_scores.append(scores.mean())\n",
    "\n",
    "print(cros_val_scores)\n",
    "\n",
    "#TODO: after cross validation we fit new model with optimal hyperparametrs\n",
    "# clf = LogisticRegression()\n",
    "#TODO: fit it\n",
    "# clf.fit(X_train, y_train)\n",
    "#TODO: make a prediction\n",
    "# log_regression_predictions = clf.predict(X_test)\n",
    "#TODO: and make scores: \n",
    "# log_regression_accuracy_score = accuracy_score(y_test, log_regression_predictions)\n",
    "# log_regression_f1_score = f1_score(y_test, log_regression_predictions, average='micro')\n",
    "# print(f\"accuracy score (in %) is {log_regression_accuracy_score*100}\")\n",
    "# print(f\"f1 score (in %) is {log_regression_f1_score*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You might use this command to install scikit-plot. \n",
    "# Warning, if you a running locally, don't call pip from within jupyter, call it from terminal in the corresponding \n",
    "# virtual environment instead\n",
    "\n",
    "# ! pip install scikit-plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. PCA: explained variance plot\n",
    "* Apply the PCA to the train part of the data. Build the explaided variance plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-c6c614740bce090e",
     "locked": false,
     "points": 10,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0c1fe666f52fe53c",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "#### 2.3. PCA trasformation\n",
    "* Select the appropriate number of components. Briefly explain your choice. Should you normalize the data?\n",
    "\n",
    "*Use `fit` and `transform` methods to transform the `train` and `test` parts.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-96ab18d96473ef71",
     "locked": false,
     "points": 5,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: From this point `sklearn` [Pipeline](https://scikit-learn.org/stable/modules/compose.html) might be useful to perform transformations on the data. Refer to the [docs](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) for more information.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d28b58a35c94e988",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "#### 2.4. Logistic regression on PCA-preprocessed data.\n",
    "* Find optimal hyperparameters for logistic regression with cross-validation on the transformed by PCA `train` data.\n",
    "\n",
    "* Estimate the model quality with `f1` and `accuracy` scores.\n",
    "* Plot a ROC-curve for the trained model. For the multiclass case you might use `scikitplot` library (e.g. `scikitplot.metrics.plot_roc(test_labels, predicted_proba)`).\n",
    "\n",
    "*Note: please, use the following hyperparameters for logistic regression: `multi_class='multinomial'`, `solver='saga'` and `tol=1e-3`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-12d53ea45258fa82",
     "locked": false,
     "points": 5,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4fbf16c64076e139",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "#### 2.5. Decision tree\n",
    "* Now train a desicion tree on the same data. Find optimal tree depth (`max_depth`) using cross-validation.\n",
    "\n",
    "* Measure the model quality using the same metrics you used above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-748ed20b51c67fab",
     "locked": false,
     "points": 15,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.40434343434343434, 0.50996632996633, 0.6594276094276095, 0.673973063973064, 0.6885521885521886, 0.674074074074074, 0.653973063973064, 0.6794276094276094, 0.6812121212121213, 0.6594612794612795, 0.6704040404040403, 0.6703703703703704, 0.6685521885521885, 0.6667340067340067]\n",
      "The max cross validation score is 0.6885521885521886 with the optimal depth is 5\n",
      "accuracy score (in %) is 69.02356902356902\n",
      "f1 score (in %) is 69.02356902356902\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# YOUR CODE HERE\n",
    "tree_depth = np.arange(1, 15, 1)\n",
    "cros_val_scores = []\n",
    "for depth in tree_depth:\n",
    "    # LogisticRegression\n",
    "    clf = DecisionTreeClassifier(max_depth=depth,\n",
    "                                 random_state=0)\n",
    "    scores = cross_val_score(clf, X_train, y_train, cv=10, scoring='accuracy')\n",
    "    cros_val_scores.append(scores.mean())\n",
    "\n",
    "print(cros_val_scores)\n",
    "print(f\"The max cross validation score is {np.max(cros_val_scores)} with the optimal depth is {np.argmax(cros_val_scores) + 1}\")\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=np.argmax(cros_val_scores) + 1,\n",
    "                            random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "prediction = clf.predict(X_test)\n",
    "\n",
    "desision_tree_accuracy_score = accuracy_score(y_test, prediction)\n",
    "desision_tree_f1_score = f1_score(y_test, prediction, average='micro')\n",
    "print(f\"accuracy score (in %) is {desision_tree_accuracy_score*100}\")\n",
    "print(f\"f1 score (in %) is {desision_tree_f1_score*100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9eadd4d8a03ae67a",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "#### 2.6. Bagging.\n",
    "Here starts the ensembling part.\n",
    "\n",
    "First we will use the __Bagging__ approach. Build an ensemble of $N$ algorithms varying N from $N_{min}=2$ to $N_{max}=100$ (with step 5).\n",
    "\n",
    "We will build two ensembles: of logistic regressions and of decision trees.\n",
    "\n",
    "*Comment: each ensemble should be constructed from models of the same family, so logistic regressions should not be mixed up with decision trees.*\n",
    "\n",
    "\n",
    "*Hint 1: To build a __Bagging__ ensebmle varying the ensemble size efficiently you might generate $N_{max}$ subsets of `train` data (of the same size as the original dataset) using bootstrap procedure once. Then you train a new instance of logistic regression/decision tree with optimal hyperparameters you estimated before on each subset (so you train it from scratch). Finally, to get an ensemble of $N$ models you average the $N$ out of $N_{max}$ models predictions.*\n",
    "\n",
    "*Hint 2: sklearn might help you with this taks. Some appropriate function/class might be out there.*\n",
    "\n",
    "* Plot `f1` and `accuracy` scores plots w.r.t. the size of the ensemble.\n",
    "\n",
    "* Briefly analyse the plot. What is the optimal number of algorithms? Explain your answer.\n",
    "\n",
    "* How do you think, are the hyperparameters for the decision trees you found in 2.5 optimal for trees used in ensemble? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-8fc95a2b206bdae1",
     "locked": false,
     "points": 35,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score (in %) is 70.37037037037037\n",
      "f1 score (in %) is 70.37037037037037\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "#* firstly do bagging with DesisionTreeClassifier\n",
    "clf = BaggingClassifier(estimator=DecisionTreeClassifier(),\n",
    "                        n_estimators=10, random_state=0).fit(X_train, y_train)\n",
    "prediction = clf.predict(X_test)\n",
    "ensemble_tree_accuracy_score = accuracy_score(y_test, prediction)\n",
    "ensemble_tree_f1_score = f1_score(y_test, prediction, average='micro')\n",
    "print(f\"accuracy score (in %) is {ensemble_tree_accuracy_score*100}\")\n",
    "print(f\"f1 score (in %) is {ensemble_tree_f1_score*100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-241b7691ab44cbfb",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "#### 2.7. Random Forest\n",
    "Now we will work with the Random Forest (its `sklearn` implementation).\n",
    "\n",
    "* * Plot `f1` and `accuracy` scores plots w.r.t. the number of trees in Random Forest.\n",
    "\n",
    "* What is the optimal number of trees you've got? Is it different from the optimal number of logistic regressions/decision trees in 2.6? Explain the results briefly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-888755d0f3d91620",
     "locked": false,
     "points": 15,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.437037037037037, 0.6702356902356902, 0.7048484848484848, 0.714074074074074, 0.7268013468013468, 0.7395959595959596, 0.7487205387205387, 0.7523232323232323, 0.7395959595959596]\n",
      "The max cross validation score is 0.7523232323232323 with the optimal depth is 8\n",
      "accuracy score (in %) is 71.04377104377105\n",
      "f1 score (in %) is 71.04377104377103\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# YOUR CODE HERE\n",
    "tree_depth = np.arange(1, 10, 1)\n",
    "cros_val_scores = []\n",
    "for depth in tree_depth:\n",
    "    # LogisticRegression\n",
    "    clf = RandomForestClassifier(max_depth=depth, n_estimators=100, random_state=0)\n",
    "    scores = cross_val_score(clf, X_train, y_train, cv=10, scoring='accuracy')\n",
    "    cros_val_scores.append(scores.mean())\n",
    "\n",
    "print(cros_val_scores)\n",
    "print(f\"The max cross validation score is {np.max(cros_val_scores)} with the optimal depth is {np.argmax(cros_val_scores) + 1}\")\n",
    "\n",
    "clf = RandomForestClassifier(max_depth=np.argmax(cros_val_scores)+1, n_estimators=100, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "prediction = clf.predict(X_test)\n",
    "\n",
    "random_forest_accuracy_score = accuracy_score(y_test, prediction)\n",
    "random_forest_f1_score = f1_score(y_test, prediction, average='micro')\n",
    "print(f\"accuracy score (in %) is {random_forest_accuracy_score*100}\")\n",
    "print(f\"f1 score (in %) is {random_forest_f1_score*100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-99191c0852538d4d",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "#### 2.8. Learning curve\n",
    "Your goal is to estimate, how does the model behaviour change with the increase of the `train` dataset size.\n",
    "\n",
    "* Split the training data into 10 equal (almost) parts. Then train the models from above (Logistic regression, Desicion Tree, Random Forest) with optimal hyperparameters you have selected on 1 part, 2 parts (combined, so the train size in increased by 2 times), 3 parts and so on.\n",
    "\n",
    "* Build a plot of `accuracy` and `f1` scores on `test` part, varying the `train` dataset size (so the axes will be score - dataset size.\n",
    "\n",
    "* Analyse the final plot. Can you make any conlusions using it? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-e39bc7e7dff61ff9",
     "locked": false,
     "points": 15,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.9. Boosting\n",
    "Your goal is to build a boosting ensemble using xgboost, CatBoost or lightgbm package.\n",
    "Please, do not use the sklearn API for these models.\n",
    "\n",
    "Find optimal number of decision trees in the boosting ensembe using grid search or other methods.\n",
    "Please, explain your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
